## Data Exploration and Validation {#sec-Chapter1}

### Dataset Overview

This chapter details the initial data exploration and validation process for the dune vegetation analysis project. The dataset consists of a primary Excel workbook (`db_species_20250214.xlsx`) containing several sheets with information about:

1. Species presence/abundance at different sampling plots (`original_data` sheet)
2. Land cover percentages at 50m and 100m radii from sample points (province-specific sheets)
3. Management practices and protection statuses for beach areas (province-specific sheets)

The data is structured by geographic region (Girona, Barcelona, and Tarragona provinces) and contains information about different beaches, transects, and plots within each region.

### Data Processing Steps

The data processing workflow follows these key steps:

1. Loading and cleaning the main dataset
2. Processing land cover data for each province 
3. Processing management data for each province
4. Validating the processed data files

All processing was implemented in R using the tidyverse ecosystem of packages, with special emphasis on data cleaning and transformation.

#### Loading the Main Dataset

The main dataset containing species observations was loaded from the `original_data` sheet of the Excel workbook. This process involved:

```{r}
#| label: load-packages
#| echo: false
#| eval: true
#| output: false
## Load required packages
library(tidyverse)
library(readxl)
library(conflicted)
library(ggplot2)
library(janitor) # For clean_names function
library(dplyr)
```

```{r}
#| label: load-data
#| echo: false
#| eval: true
#| output: false
## Load the main data sheet
main_data <- read_excel("../data/db_species_20250214.xlsx", sheet = "original_data")
main_data <- main_data %>% select(where(~ !all(is.na(.))))

## Clean column names using the janitor package
main_data <- main_data %>% janitor::clean_names()
```

This initial loading process removed completely empty columns and standardized column names using the `clean_names()` function, which converts column names to lowercase, replaces spaces with underscores, and removes special characters.

#### Numeric Column Conversion

The species abundance data needed to be converted to numeric format for analysis. The script identified the relevant columns and performed the conversion:

```{r}
#| label: numeric-conversion
#| echo: false
#| eval: true
## Find the index of the EUNIS column
eunis_col_index <- which(grepl("eunis", names(main_data), ignore.case = TRUE))
if(length(eunis_col_index) == 0) {
  cat("Warning: Could not find 'EUNIS' column. Will parse all columns from second onwards.\n")
  eunis_col_index <- ncol(main_data) + 1  # Set to beyond the last column
} else {
  eunis_col_index <- min(eunis_col_index)  # Take the first match if multiple
}

## Parse columns from second to EUNIS as numeric
for(i in 2:min(ncol(main_data), eunis_col_index - 1)) {
  col_name <- names(main_data)[i]
  # Store the original values to check for parsing issues
  original_values <- main_data[[i]]

  # Try to convert to numeric
  main_data[[i]] <- as.numeric(as.character(main_data[[i]]))

  # Check if we lost any non-NA values
  if(sum(!is.na(original_values)) > sum(!is.na(main_data[[i]]))) {
    warning_msg <- paste("Warning: Some values in column", col_name, "could not be parsed as numeric")
    cat(warning_msg, "\n")

    # Report the problematic values
    problematic <- original_values[!is.na(original_values) & is.na(main_data[[i]])]
    if(length(problematic) > 0) {
      cat("  Problematic values:", toString(head(unique(problematic), 5)), "\n")
    }
  }
}
```

This conversion process included validation checks to identify any values that could not be properly converted to numeric format, ensuring data quality through the transformation.

#### Column Reordering

To ensure consistency in data structure, the columns were reordered to follow a specific pattern:

```{r}
#| label: column-reorder
#| echo: false
#| eval: true
## Identify all desired columns
species_cols <- setdiff(names(main_data),
                      c("plot", "id_beach", "beach", "id_transect", "id_plot", "transect", "eunis"))

## Create the desired column order
ordered_cols <- c("plot", "id_beach", "beach", "id_transect", "id_plot", "transect", "eunis", species_cols)
## Reorder columns (only those that exist)
main_data <- main_data %>% select(all_of(ordered_cols), everything())

## Save the processed main data
save(main_data, file = "../data/processed_data_clean.RData")
```

The reordering placed identifier columns first, followed by the species columns, making the data structure more intuitive for subsequent analysis.

#### Processing Land Cover Data

For each province (Girona, Barcelona, and Tarragona), the land cover data was processed using a dedicated function:

```{r}
#| label: land-cover-processing
#| echo: false
#| eval: true
## Function to process land cover sheets
process_land_cover <- function(sheet_name) {
  cat("Processing sheet:", sheet_name, "\n")

  # Read the sheet
  land_cover_data <- read_excel("../data/db_species_20250214.xlsx", sheet = sheet_name)

  # Clean column names
  land_cover_data <- land_cover_data %>% janitor::clean_names()

  # Select id_beach/id_plot column
  id_col <- grep("^id_beach$|^id_plot$", names(land_cover_data), value = TRUE)[1]
  if(is.na(id_col)) {
    id_col <- grep("id.*beach|beach.*id|id.*plot|plot.*id", names(land_cover_data), value = TRUE)[1]
  }

  # Get 50m and 100m columns
  cols_50m <- grep("^(x)?50m_", names(land_cover_data), value = TRUE)
  cols_100m <- grep("^(x)?100m_", names(land_cover_data), value = TRUE)

  if(length(cols_50m) == 0) {
    cols_50m <- grep("50.*m|50m|50 m", names(land_cover_data), value = TRUE)
  }

  if(length(cols_100m) == 0) {
    cols_100m <- grep("100.*m|100m|100 m", names(land_cover_data), value = TRUE)
  }

  # Select columns
  distance_cols <- c(cols_50m, cols_100m)
  selected_cols <- c(id_col, distance_cols)

  # Filter data
  filtered_data <- land_cover_data %>% select(all_of(selected_cols)) %>% distinct()

  # Convert columns to numeric if needed
  for(col in distance_cols) {
    filtered_data[[col]] <- as.numeric(filtered_data[[col]])
  }

  # Convert ID column to integer
  filtered_data[[id_col]] <- as.integer(filtered_data[[id_col]])

  return(filtered_data)
}

## Process each land cover sheet
girona_land_cover <- process_land_cover("girona_land cover")
barcelona_land_cover <- process_land_cover("barcelona_land cover")
tarragona_land_cover <- process_land_cover("tarragona_land cover")

## Create a list containing all land cover datasets
land_cover_data <- list(
  "Girona" = girona_land_cover,
  "Barcelona" = barcelona_land_cover,
  "Tarragona" = tarragona_land_cover
)

## Save the combined land cover data
save(land_cover_data, file = "../data/all_land_cover_data.RData")
```

This processing function:

1. Identifies the ID column (beach or plot identifier)
2. Extracts columns related to 50m and 100m land cover measurements
3. Filters to keep only necessary columns
4. Converts all measurements to numeric format
5. Returns a standardized data frame for each province

#### Processing Management Data

The management data followed a similar processing pattern, but with special handling for categorical variables:

```{r}
#| label: management-data-processing
#| echo: false
#| eval: true
## Function to process management sheets
process_management <- function(sheet_name) {
  cat("Processing sheet:", sheet_name, "\n")

  # Read the sheet
  management_data <- read_excel("../data/db_species_20250214.xlsx", sheet = sheet_name)

  # Clean column names
  management_data <- management_data %>% janitor::clean_names()

  # Standardize key column names based on what is expected
  expected_cols <- c(
    "id_plot", "id_beach", "beach",
    "managed_paths", "rope_fences", "mechanical_cleaning",
    "surface_area_occupied_by_seasonal_services_and_amenities_on_or_less_than_5_m_from_the_dunes",
    "surface_area_of_parking_or_other_fixed_services_on_or_less_than_5_m_from_the_dunes",
    "protection_of_the_system_and_the_immediate_environment",
    "degree_of_protection_according_to_the_iucn_classification"
  )

  # Find matching columns
  actual_cols <- vector("character", length(expected_cols))
  for (i in seq_along(expected_cols)) {
    pattern <- expected_cols[i]
    simple_pattern <- gsub("_", ".*", pattern)
    matches <- grep(simple_pattern, names(management_data), ignore.case = TRUE, value = TRUE)

    if (length(matches) > 0) {
      actual_cols[i] <- matches[1]
    } else {
      cat("Warning: Could not find a column matching '", expected_cols[i], "'\n", sep = "")
      actual_cols[i] <- NA
    }
  }

  # Remove NA values
  actual_cols <- actual_cols[!is.na(actual_cols)]

  if (length(actual_cols) > 0) {
    # Subset the original data
    filtered_data <- management_data %>% select(all_of(actual_cols))

    # Detect ID columns
    id_plot_col <- grep("id.*plot|plot.*id", names(filtered_data), ignore.case = TRUE, value = TRUE)[1]
    id_beach_col <- grep("id.*beach|beach.*id", names(filtered_data), ignore.case = TRUE, value = TRUE)[1]

    # Ensure ID columns are integers
    if (!is.na(id_plot_col)) {
      filtered_data[[id_plot_col]] <- as.integer(filtered_data[[id_plot_col]])
    }

    if (!is.na(id_beach_col)) {
      filtered_data[[id_beach_col]] <- as.integer(filtered_data[[id_beach_col]])
    }

    # Convert appropriate columns to factors if they have categorical values
    for (col in names(filtered_data)) {
      if (is.character(filtered_data[[col]]) &&
          !grepl("^id|^beach$", col, ignore.case = TRUE)) {
        unique_vals <- unique(na.omit(filtered_data[[col]]))
        if (length(unique_vals) < 10) {  # Assume categorical if fewer than 10 unique values
          filtered_data[[col]] <- factor(filtered_data[[col]])
        }
      }
    }

    return(filtered_data)
  } else {
    warning("No usable columns found in the management sheet")
    return(NULL)
  }
}

## Process each management sheet
girona_management <- process_management("girona_management")
barcelona_management <- process_management("barcelona_management")
tarragona_management <- process_management("tarragona_management")

## Create a list containing all management datasets
management_data <- list(
  "Girona" = girona_management,
  "Barcelona" = barcelona_management,
  "Tarragona" = tarragona_management
)

## Save the combined management data
save(management_data, file = "../data/all_management_data.RData")
```

This processing function:

1. Attempts to locate columns matching expected management variables
2. Converts ID columns to integer format
3. Intelligently converts categorical variables to factors
4. Returns a standardized data frame for each province

### Data Validation

After the initial data processing, a validation script was executed to ensure data quality and integrity. The validation process included:

1. Checking the dimensions of the processed datasets
2. Verifying column presence and order
3. Validating value ranges and formats
4. Cross-checking relationships between identifier fields

#### Main Data Validation

The main data validation included these key checks:

```{r}
#| label: main-data-validation
#| echo: false
#| eval: true
validate_main_data <- function(data) {
  cat("===== Validating main_data =====\n\n")

  # Check dimensions
  expected_rows <- 278
  expected_cols <- 147 + 7  # Species columns + identifier columns

  cat("Dimensions check:\n")
  cat("  Expected: ", expected_cols, " columns by ", expected_rows, " rows\n", sep = "")
  cat("  Actual:   ", ncol(data), " columns by ", nrow(data), " rows\n", sep = "")

  if (nrow(data) != expected_rows) {
    cat("  WARNING: Row count does not match expected value!\n")
  }

  if (ncol(data) < expected_cols - 5 || ncol(data) > expected_cols + 5) {
    cat("  WARNING: Column count is significantly different from expected value!\n")
  }

  # Check column existence and order
  expected_first_cols <- c("plot", "id_beach", "beach", "id_transect", "id_plot", "transect", "eunis")

  cat("\nColumn presence check:\n")
  for (col in expected_first_cols) {
    if (col %in% names(data)) {
      cat("  Column '", col, "' is present at position ", which(names(data) == col), "\n", sep = "")
    } else {
      cat("  WARNING: Column '", col, "' is missing!\n", sep = "")
    }
  }

  # Validate column formats
  cat("\nColumn format validation:\n")

  # Check plot format (D+_D+_D+)
  if ("plot" %in% names(data)) {
    plot_format_check <- all(grepl("^\\d+_\\d+_\\d+$", data$plot))
    cat("  'plot' format (D+_D+_D+): ", ifelse(plot_format_check, "VALID", "INVALID"), "\n", sep = "")
    if (!plot_format_check) {
      invalid_plots <- data$plot[!grepl("^\\d+_\\d+_\\d+$", data$plot)]
      cat("    Invalid examples: ", toString(head(invalid_plots, 5)), "\n", sep = "")
    }
  }

  # Check id_beach format (D+)
  if ("id_beach" %in% names(data)) {
    id_beach_format_check <- all(grepl("^\\d+$", as.character(data$id_beach)))
    cat("  'id_beach' format (D+): ", ifelse(id_beach_format_check, "VALID", "INVALID"), "\n", sep = "")
    if (!id_beach_format_check) {
      invalid_id_beach <- data$id_beach[!grepl("^\\d+$", as.character(data$id_beach))]
      cat("    Invalid examples: ", toString(head(invalid_id_beach, 5)), "\n", sep = "")
    }
  }

  # Check id_transect format (D+)
  if ("id_transect" %in% names(data)) {
    id_transect_format_check <- all(grepl("^\\d+$", as.character(data$id_transect)))
    cat("  'id_transect' format (D+): ", ifelse(id_transect_format_check, "VALID", "INVALID"), "\n", sep = "")
    if (!id_transect_format_check) {
      invalid_id_transect <- data$id_transect[!grepl("^\\d+$", as.character(data$id_transect))]
      cat("    Invalid examples: ", toString(head(invalid_id_transect, 5)), "\n", sep = "")
    }
  }

  # Check id_plot format (D+)
  if ("id_plot" %in% names(data)) {
    id_plot_format_check <- all(grepl("^\\d+$", as.character(data$id_plot)))
    cat("  'id_plot' format (D+): ", ifelse(id_plot_format_check, "VALID", "INVALID"), "\n", sep = "")
    if (!id_plot_format_check) {
      invalid_id_plot <- data$id_plot[!grepl("^\\d+$", as.character(data$id_plot))]
      cat("    Invalid examples: ", toString(head(invalid_id_plot, 5)), "\n", sep = "")
    }
  }

  # Check transect format (D+_D+)
  if ("transect" %in% names(data)) {
    transect_format_check <- all(grepl("^\\d+_\\d+$", as.character(data$transect)))
    cat("  'transect' format (D+_D+): ", ifelse(transect_format_check, "VALID", "INVALID"), "\n", sep = "")
    if (!transect_format_check) {
      invalid_transect <- data$transect[!grepl("^\\d+_\\d+$", as.character(data$transect))]
      cat("    Invalid examples: ", toString(head(invalid_transect, 5)), "\n", sep = "")
    }
  }

  # Validate that plot is the concatenation of id_beach, id_transect, and id_plot
  if (all(c("plot", "id_beach", "id_transect", "id_plot") %in% names(data))) {
    cat("\nValidating plot concatenation:\n")
    # Build expected plot values
    expected_plot <- paste(data$id_beach, data$id_transect, data$id_plot, sep = "_")
    plot_match <- all(data$plot == expected_plot)

    cat("  'plot' matches concatenation of id_beach_id_transect_id_plot: ",
        ifelse(plot_match, "VALID", "INVALID"), "\n", sep = "")

    if (!plot_match) {
      # Find mismatches and display examples
      mismatches <- which(data$plot != expected_plot)
      if (length(mismatches) > 0) {
        cat("    Mismatches (first 5):\n")
        for (i in head(mismatches, 5)) {
          cat("      Row ", i, ": plot='", data$plot[i],
              "', expected='", expected_plot[i], "'\n", sep = "")
        }
      }
    }
  } else {
    cat("\nCannot validate plot concatenation - one or more required columns missing\n")
  }

  # Validate all species columns (from column 8 to the end) have values between 0 and 5
  cat("\nValidating species abundance values (0-5):\n")

  # Find the index of the first species column
  first_species_idx <- max(which(names(data) %in% expected_first_cols)) + 1

  if (first_species_idx <= ncol(data)) {
    species_cols <- names(data)[first_species_idx:ncol(data)]
    cat("  Checking", length(species_cols), "species columns\n")

    # Function to check if column has valid values (0-5)
    check_species_col <- function(col_name) {
      values <- data[[col_name]]
      valid_values <- (values >= 0 & values <= 5 & values == floor(values))
      return(all(valid_values))
    }

    # Apply check to all species columns
    species_check_results <- sapply(species_cols, check_species_col)

    # Report results
    valid_cols <- sum(species_check_results)
    invalid_cols <- sum(!species_check_results)

    cat("  Valid columns (integers 0-5):", valid_cols, "\n")
    cat("  Invalid columns:", invalid_cols, "\n")

    if (invalid_cols > 0) {
      cat("  Invalid column names: ",
          toString(head(names(species_check_results)[!species_check_results], 5)), "\n", sep = "")

      # Show examples of invalid values for the first few invalid columns
      for (col in head(names(species_check_results)[!species_check_results], 3)) {
        values <- data[[col]]
        invalid_values <- values[!((values >= 0 & values <= 5 & values == floor(values)))]
        cat("    Column '", col, "' invalid values: ", toString(head(invalid_values, 5)), "\n", sep = "")
      }
    }
  } else {
    cat("  WARNING: Could not find species columns after identifier columns!\n")
  }

  cat("\nMain data validation complete.\n")
  cat("=============================================\n\n")
}
```

#### Land Cover Data Validation

Validation for the land cover data focused on:

```{r}
#| label: land-cover-validation
#| echo: false
#| eval: true
validate_land_cover_data <- function(data) {
  cat("===== Validating land_cover_data =====\n\n")

  # Check if it's a list with expected regions
  expected_regions <- c("Girona", "Barcelona", "Tarragona")
  expected_rows <- c("Girona" = 19, "Barcelona" = 4, "Tarragona" = 16)

  cat("Region presence check:\n")
  for (region in expected_regions) {
    if (region %in% names(data)) {
      cat("  Region '", region, "' is present with ", nrow(data[[region]]), " observations\n", sep = "")

      # Check row count
      if (nrow(data[[region]]) != expected_rows[region]) {
        cat("  WARNING: Expected ", expected_rows[region], " rows for ",
            region, ", but found ", nrow(data[[region]]), "\n", sep = "")
      }
    } else {
      cat("  WARNING: Region '", region, "' is missing!\n", sep = "")
    }
  }

  # Expected column patterns for land cover data
  id_col_pattern <- "^id_beach$"
  expected_50m_patterns <- c(
    "scrubland", "grassland", "communication_routes", "urban",
    "forestry_bare_soil", "forests", "lagoon_and_salt_marshes",
    "crops", "freshwater"
  )

  # Validate each region's data structure
  cat("\nValidating data structure for each region:\n")

  for (region in intersect(names(data), expected_regions)) {
    region_data <- data[[region]]
    cat("\n  Region:", region, "\n")

    # Check for 19 columns (id_beach + 9 for 50m + 9 for 100m)
    cat("  Column count:", ncol(region_data), "(expected 19)\n")
    if (ncol(region_data) != 19) {
      cat("  WARNING: Expected 19 columns, found", ncol(region_data), "\n")
    }

    # Check for id_beach column
    id_cols <- grep(id_col_pattern, names(region_data), value = TRUE)
    if (length(id_cols) > 0) {
      cat("  ID column found:", id_cols[1], "\n")
    } else {
      cat("  WARNING: No 'id_beach' column found!\n")
    }

    # Find 50m and 100m columns
    cols_50m <- grep("50m|50 m|x50", names(region_data), ignore.case = TRUE, value = TRUE)
    cols_100m <- grep("100m|100 m|x100", names(region_data), ignore.case = TRUE, value = TRUE)

    cat("  Found", length(cols_50m), "columns for 50m land cover (expected 9)\n")
    cat("  Found", length(cols_100m), "columns for 100m land cover (expected 9)\n")

    # Check for expected land cover types in 50m columns
    cat("\n  Checking for expected 50m land cover types:\n")
    for (pattern in expected_50m_patterns) {
      matches <- grep(pattern, cols_50m, ignore.case = TRUE, value = TRUE)
      if (length(matches) <= 0) {
        cat("    WARNING: No column matching '", pattern, "' pattern for 50m\n", sep = "")
      }
    }

    # Check for expected land cover types in 100m columns
    cat("\n  Checking for expected 100m land cover types:\n")
    for (pattern in expected_50m_patterns) {
      matches <- grep(pattern, cols_100m, ignore.case = TRUE, value = TRUE)
      if (length(matches) <= 0) {
        cat("    WARNING: No column matching '", pattern, "' pattern for 100m\n", sep = "")
      }
    }

    # Check if all columns are numeric
    numeric_cols <- sapply(region_data, is.numeric)
    cat("\n  Numeric columns:", sum(numeric_cols), "out of", ncol(region_data), "\n")
    if (sum(!numeric_cols) > 0) {
      cat("  WARNING: The following columns are not numeric:\n")
      for (col in names(region_data)[!numeric_cols]) {
        cat("    '", col, "' (class: ", class(region_data[[col]]), ")\n", sep = "")
      }
    }

    # Validate that 50m columns sum to 100 (allowing for rounding errors)
    if (length(cols_50m) > 0) {
      cat("\n  Validating 50m columns sum to 100%:\n")

      # Calculate row sums for 50m columns
      row_sums_50m <- rowSums(region_data[, cols_50m, drop = FALSE], na.rm = TRUE)
      valid_sums <- abs(row_sums_50m - 100) <= 0.15  # Allow for small rounding errors

      cat("    Rows with valid sums (approx 100%):", sum(valid_sums), "out of", length(row_sums_50m), "\n")
      if (sum(!valid_sums) > 0) {
        cat("    WARNING: The following rows have 50m sums significantly different from 100%:\n")
        invalid_rows <- which(!valid_sums)
        for (i in head(invalid_rows, 5)) {
          cat("      Row ", i, " (id_beach=", region_data$id_beach[i],
              "): sum = ", row_sums_50m[i], "\n", sep = "")
        }
      }
    }

    # Validate that 100m columns sum to 100 (allowing for rounding errors)
    if (length(cols_100m) > 0) {
      cat("\n  Validating 100m columns sum to 100%:\n")

      # Calculate row sums for 100m columns
      row_sums_100m <- rowSums(region_data[, cols_100m, drop = FALSE], na.rm = TRUE)
      valid_sums <- abs(row_sums_100m - 100) <= 0.15  # Allow for small rounding errors

      cat("    Rows with valid sums (approx 100%):", sum(valid_sums), "out of", length(row_sums_100m), "\n")
      if (sum(!valid_sums) > 0) {
        cat("    WARNING: The following rows have 100m sums significantly different from 100%:\n")
        invalid_rows <- which(!valid_sums)
        for (i in head(invalid_rows, 5)) {
          cat("      Row ", i, " (id_beach=", region_data$id_beach[i],
              "): sum = ", row_sums_100m[i], "\n", sep = "")
        }
      }
    }
  }

  cat("\nLand cover data validation complete.\n")
  cat("=============================================\n\n")
}
```

The key validation for the land cover data was ensuring that the percentages for different land cover types at each distance (50m and 100m) summed to approximately 100%.

#### Management Data Validation

The management data validation focused on:

```{r}
#| label: management-validation
#| echo: false
#| eval: true
validate_management_data <- function(data) {
  cat("===== Validating management_data =====\n\n")

  # Check if it's a list with expected regions
  expected_regions <- c("Girona", "Barcelona", "Tarragona")
  expected_rows <- c("Girona" = 19, "Barcelona" = 4, "Tarragona" = 16)

  cat("Region presence check:\n")
  for (region in expected_regions) {
    if (region %in% names(data)) {
      cat("  Region '", region, "' is present with ", nrow(data[[region]]), " observations\n", sep = "")

      # Check row count
      if (nrow(data[[region]]) != expected_rows[region]) {
        cat("  WARNING: Expected ", expected_rows[region], " rows for ",
            region, ", but found ", nrow(data[[region]]), "\n", sep = "")
      }
    } else {
      cat("  WARNING: Region '", region, "' is missing!\n", sep = "")
    }
  }

  # Expected columns for management data
  expected_columns <- c("id_plot", "id_beach",
                        "managed_paths", "rope_fences", "mechanical_cleaning",
                        "surface_area_occupied_by_seasonal_services_and_amenities_on_or_less_than_5_m_from_the_dunes",
                        "surface_area_of_parking_or_other_fixed_services_on_or_less_than_5_m_from_the_dunes",
                        "protection_of_the_system_and_the_immediate_environment",
                        "degree_of_protection_according_to_the_iucn_classification")

  # Validate each region's data structure
  cat("\nValidating data structure for each region:\n")

  for (region in intersect(names(data), expected_regions)) {
    region_data <- data[[region]]
    cat("\n  Region:", region, "\n")

    # Check columns exist
    cat("  Column presence check:\n")
    missing_cols <- setdiff(expected_columns, names(region_data))
    present_cols <- intersect(expected_columns, names(region_data))

    cat("  Present expected columns:", length(present_cols), "out of", length(expected_columns), "\n")
    if (length(missing_cols) > 0) {
      cat("  WARNING: Missing expected columns:", toString(missing_cols), "\n")
    }

    # Validate that management rating columns only contain integer values 0-5
    # These are all columns from managed_paths onwards
    management_cols <- expected_columns[4:length(expected_columns)]
    present_management_cols <- intersect(management_cols, names(region_data))

    cat("\n  Validating management rating columns (integers 0-5):\n")

    # Function to check if column has valid values (0-5 integer values)
    check_management_col <- function(col_name) {
      values <- region_data[[col_name]]
      valid_values <- (values >= 0 & values <= 5 & values == floor(values))
      return(list(
        valid = all(valid_values),
        invalid_values = values[!valid_values]
      ))
    }

    # Apply check to all management columns
    for (col in present_management_cols) {
      col_check <- check_management_col(col)
      cat("  Column '", col, "': ", ifelse(col_check$valid, "VALID", "INVALID"), "\n", sep = "")

      # If invalid, show examples
      if (!col_check$valid) {
        cat("    Invalid values: ", toString(head(col_check$invalid_values, 5)), "\n", sep = "")
      }
    }
  }

  cat("\nManagement data validation complete.\n")
  cat("=============================================\n\n")
}
```

The most important validation for management data was ensuring that the management rating columns contained only integer values between 0 and 5.

### Executing the Validation

After creating the validation functions, they need to be executed on the processed data files. This is done by loading each of the saved RData files and passing them to the appropriate validation function:

```{r}
#| label: execute-validation
#| echo: true
#| eval: true
## Load the required libraries
cat("Starting data validation...\n\n")

## Load main_data
cat("Loading main_data...\n")
if (file.exists("../data/processed_data_clean.RData")) {
  load("../data/processed_data_clean.RData")
  validate_main_data(main_data)
} else {
  cat("ERROR: File 'data/processed_data_clean.RData' not found!\n\n")
}

## Load land_cover_data
cat("Loading land_cover_data...\n")
if (file.exists("../data/all_land_cover_data.RData")) {
  load("../data/all_land_cover_data.RData")
  validate_land_cover_data(land_cover_data)
} else {
  cat("ERROR: File 'data/all_land_cover_data.RData' not found!\n\n")
}

## Load management_data (placeholder for future implementation)
cat("Loading management_data...\n")
if (file.exists("../data/all_management_data.RData")) {
  load("../data/all_management_data.RData")
  validate_management_data(management_data)
} else {
  cat("ERROR: File 'data/all_management_data.RData' not found!\n\n")
}

cat("Validation complete.\n")
```

This execution block:

1. Loads the necessary libraries
2. Sets conflict resolution preferences for common function names
3. Attempts to load each of the processed data files
4. Executes the appropriate validation function for each dataset
5. Prints appropriate error messages if files cannot be found

The validation process provides a comprehensive report on the quality and consistency of the processed data, identifying any issues that need to be addressed before proceeding with further analysis.

### Summary

The data exploration and validation process established a solid foundation for further analysis by:

1. Loading and cleaning the raw data from the Excel workbook
2. Standardizing column names and formats
3. Converting data types appropriately for future analysis
4. Structuring the data consistently across geographical regions
5. Validating the integrity and quality of the processed datasets

The resulting processed datasets were saved as RData files for efficient loading in subsequent analysis steps:

1. `processed_data_clean.RData` - Main species observations dataset
2. `all_land_cover_data.RData` - Land cover percentages for each province
3. `all_management_data.RData` - Management practices for each province

These processed files form the basis for the exploratory data analysis and modeling presented in subsequent chapters.
